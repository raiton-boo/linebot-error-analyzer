# ğŸš€ é«˜åº¦ãªä½¿ç”¨ä¾‹

å®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ã®é«˜åº¦ãªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æœ€é©åŒ–æ‰‹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

## ğŸ¢ ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ©ãƒ¼ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

### 1. ãƒãƒ«ãƒã‚µãƒ¼ãƒ“ã‚¹å¯¾å¿œã‚¨ãƒ©ãƒ¼ãƒãƒ–

è¤‡æ•°ã® LINE Bot ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¸€å…ƒç®¡ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

```python
import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass, field
from collections import defaultdict
from linebot_error_analyzer import AsyncLineErrorAnalyzer

@dataclass
class ServiceConfig:
    """ã‚µãƒ¼ãƒ“ã‚¹è¨­å®š"""
    service_id: str
    service_name: str
    channel_access_token: str
    alert_threshold: int = 100  # 1æ™‚é–“ã‚ãŸã‚Šã®ã‚¨ãƒ©ãƒ¼é–¾å€¤
    critical_categories: List[str] = field(default_factory=lambda: ["AUTH_ERROR", "SERVER_ERROR"])

class EnterpriseErrorHub:
    """ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚¨ãƒ©ãƒ¼ç›£è¦–ãƒãƒ–"""

    def __init__(self, services: List[ServiceConfig]):
        self.services = {s.service_id: s for s in services}
        self.analyzer = AsyncLineErrorAnalyzer()
        self.analyzer.enable_caching(50000)  # å¤§å®¹é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥

        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
        self.error_storage = defaultdict(lambda: defaultdict(list))
        self.service_stats = defaultdict(lambda: {
            "total_errors": 0,
            "critical_errors": 0,
            "last_alert": None
        })

        # ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†
        self.alert_cooldown = timedelta(minutes=15)  # ã‚¢ãƒ©ãƒ¼ãƒˆé–“éš”

        # ãƒ­ã‚°è¨­å®š
        self.setup_logging()

    def setup_logging(self):
        """æ§‹é€ åŒ–ãƒ­ã‚°ã®è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('enterprise_errors.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('enterprise_error_hub')

    async def process_error_batch(self, service_id: str, errors: List[dict]) -> List[dict]:
        """ã‚¨ãƒ©ãƒ¼ãƒãƒƒãƒã®å‡¦ç†"""

        if service_id not in self.services:
            self.logger.warning(f"Unknown service: {service_id}")
            return []

        service = self.services[service_id]

        # ãƒãƒƒãƒåˆ†æå®Ÿè¡Œ
        results = await self.analyzer.analyze_batch(errors, batch_size=100)

        processed_results = []
        critical_count = 0

        for error, result in zip(errors, results):
            # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã®æ‹¡å¼µ
            enriched_result = {
                "service_id": service_id,
                "service_name": service.service_name,
                "timestamp": datetime.now().isoformat(),
                "analysis": result.to_dict(),
                "original_error": error
            }

            processed_results.append(enriched_result)

            # çµ±è¨ˆæ›´æ–°
            await self.update_service_stats(service_id, result)

            # é‡è¦ã‚¨ãƒ©ãƒ¼ã®ã‚«ã‚¦ãƒ³ãƒˆ
            if result.category.value in service.critical_categories:
                critical_count += 1

            # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜
            hour_key = datetime.now().strftime("%Y-%m-%d-%H")
            self.error_storage[service_id][hour_key].append(enriched_result)

        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        if critical_count > 0:
            await self.check_and_send_alerts(service_id, critical_count)

        return processed_results

    async def update_service_stats(self, service_id: str, result):
        """ã‚µãƒ¼ãƒ“ã‚¹çµ±è¨ˆã®æ›´æ–°"""

        stats = self.service_stats[service_id]
        stats["total_errors"] += 1

        if result.severity.value in ["CRITICAL", "HIGH"]:
            stats["critical_errors"] += 1

    async def check_and_send_alerts(self, service_id: str, critical_count: int):
        """ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ãƒã‚§ãƒƒã‚¯ã¨é€ä¿¡"""

        service = self.services[service_id]
        stats = self.service_stats[service_id]

        # å‰å›ã‚¢ãƒ©ãƒ¼ãƒˆã‹ã‚‰ã®æ™‚é–“ãƒã‚§ãƒƒã‚¯
        if stats["last_alert"] and datetime.now() - stats["last_alert"] < self.alert_cooldown:
            return

        # 1æ™‚é–“ä»¥å†…ã®ã‚¨ãƒ©ãƒ¼æ•°ãƒã‚§ãƒƒã‚¯
        hour_key = datetime.now().strftime("%Y-%m-%d-%H")
        recent_errors = len(self.error_storage[service_id][hour_key])

        if recent_errors >= service.alert_threshold:
            await self.send_critical_alert(
                service_id,
                f"é«˜é »åº¦ã‚¨ãƒ©ãƒ¼æ¤œå‡º: {recent_errors}ä»¶/æ™‚é–“ (é–¾å€¤: {service.alert_threshold})"
            )
            stats["last_alert"] = datetime.now()

        if critical_count >= 10:  # é‡è¦ã‚¨ãƒ©ãƒ¼ãŒ10ä»¶ä»¥ä¸Š
            await self.send_critical_alert(
                service_id,
                f"é‡è¦ã‚¨ãƒ©ãƒ¼å¤šç™º: {critical_count}ä»¶ã®é‡è¦ã‚¨ãƒ©ãƒ¼"
            )

    async def send_critical_alert(self, service_id: str, message: str):
        """é‡è¦ã‚¢ãƒ©ãƒ¼ãƒˆã®é€ä¿¡"""

        service = self.services[service_id]

        alert_data = {
            "timestamp": datetime.now().isoformat(),
            "service_id": service_id,
            "service_name": service.service_name,
            "alert_type": "CRITICAL",
            "message": message,
            "stats": self.get_service_summary(service_id)
        }

        # ãƒ­ã‚°å‡ºåŠ›
        self.logger.critical(json.dumps(alert_data, ensure_ascii=False))

        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ Slackã€ãƒ¡ãƒ¼ãƒ«ã€PagerDutyç­‰ã«é€ä¿¡
        print(f"ğŸš¨ CRITICAL ALERT: {message}")

        # Webhooké€šçŸ¥ã®ä¾‹
        await self.notify_webhook(alert_data)

    async def notify_webhook(self, alert_data: dict):
        """Webhooké€šçŸ¥ã®é€ä¿¡"""

        # å®Ÿè£…ä¾‹ï¼šSlack Webhook
        import aiohttp

        webhook_url = "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

        slack_message = {
            "text": f"ğŸš¨ LINE Bot Error Alert",
            "attachments": [{
                "color": "danger",
                "fields": [
                    {"title": "Service", "value": alert_data["service_name"], "short": True},
                    {"title": "Alert Type", "value": alert_data["alert_type"], "short": True},
                    {"title": "Message", "value": alert_data["message"], "short": False}
                ]
            }]
        }

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(webhook_url, json=slack_message) as response:
                    if response.status == 200:
                        self.logger.info("Slack notification sent successfully")
                    else:
                        self.logger.error(f"Failed to send Slack notification: {response.status}")
        except Exception as e:
            self.logger.error(f"Webhook notification error: {e}")

    def get_service_summary(self, service_id: str) -> dict:
        """ã‚µãƒ¼ãƒ“ã‚¹çµ±è¨ˆã‚µãƒãƒªãƒ¼"""

        stats = self.service_stats[service_id]

        # éå»24æ™‚é–“ã®ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
        now = datetime.now()
        recent_errors = []

        for i in range(24):
            hour_key = (now - timedelta(hours=i)).strftime("%Y-%m-%d-%H")
            hour_errors = self.error_storage[service_id][hour_key]
            recent_errors.extend(hour_errors)

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        category_stats = defaultdict(int)
        for error in recent_errors:
            category = error["analysis"]["category"]
            category_stats[category] += 1

        return {
            "total_errors_24h": len(recent_errors),
            "critical_errors_24h": stats["critical_errors"],
            "category_breakdown": dict(category_stats),
            "last_alert": stats["last_alert"].isoformat() if stats["last_alert"] else None
        }

    async def get_dashboard_data(self) -> dict:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ã®å–å¾—"""

        dashboard_data = {
            "timestamp": datetime.now().isoformat(),
            "services": {}
        }

        for service_id, service in self.services.items():
            dashboard_data["services"][service_id] = {
                "service_name": service.service_name,
                "summary": self.get_service_summary(service_id),
                "analyzer_stats": self.analyzer.get_analysis_stats()
            }

        return dashboard_data

# ä½¿ç”¨ä¾‹
async def setup_enterprise_monitoring():
    """ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç›£è¦–ã®è¨­å®š"""

    services = [
        ServiceConfig(
            service_id="customer_support_bot",
            service_name="ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆBot",
            channel_access_token="token1",
            alert_threshold=50
        ),
        ServiceConfig(
            service_id="marketing_bot",
            service_name="ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°Bot",
            channel_access_token="token2",
            alert_threshold=100
        ),
        ServiceConfig(
            service_id="internal_bot",
            service_name="å†…éƒ¨é€šçŸ¥Bot",
            channel_access_token="token3",
            alert_threshold=20
        )
    ]

    hub = EnterpriseErrorHub(services)

    # ã‚¨ãƒ©ãƒ¼ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å‡¦ç†ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å¤–éƒ¨ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å–å¾—ï¼‰
    while True:
        try:
            # å„ã‚µãƒ¼ãƒ“ã‚¹ã‹ã‚‰ã®ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†
            for service_id in hub.services.keys():
                errors = await get_errors_from_service(service_id)  # å®Ÿè£…ä¾å­˜

                if errors:
                    results = await hub.process_error_batch(service_id, errors)
                    print(f"Processed {len(results)} errors for {service_id}")

            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
            dashboard_data = await hub.get_dashboard_data()
            await update_dashboard(dashboard_data)  # å®Ÿè£…ä¾å­˜

            await asyncio.sleep(30)  # 30ç§’é–“éš”

        except Exception as e:
            logging.error(f"Monitoring loop error: {e}")
            await asyncio.sleep(60)
```

### 2. è‡ªå‹•å¾©æ—§ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ã‚·ã‚¹ãƒ†ãƒ 

```python
import asyncio
from typing import Callable, Any, List, Optional
from dataclasses import dataclass
from enum import Enum

class RecoveryStrategy(Enum):
    """å¾©æ—§æˆ¦ç•¥"""
    RETRY = "retry"
    FALLBACK = "fallback"
    CIRCUIT_BREAKER = "circuit_breaker"
    BACKOFF = "exponential_backoff"

@dataclass
class RecoveryConfig:
    """å¾©æ—§è¨­å®š"""
    max_retries: int = 3
    base_delay: float = 1.0
    max_delay: float = 60.0
    backoff_multiplier: float = 2.0
    circuit_breaker_threshold: int = 5
    circuit_breaker_timeout: float = 300.0  # 5åˆ†

class SmartRecoverySystem:
    """ã‚¹ãƒãƒ¼ãƒˆè‡ªå‹•å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, config: RecoveryConfig):
        self.config = config
        self.analyzer = AsyncLineErrorAnalyzer()

        # ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼çŠ¶æ…‹ç®¡ç†
        self.circuit_states = {}
        self.failure_counts = defaultdict(int)
        self.last_failure_times = {}

        # å¾©æ—§æˆ¦ç•¥ãƒãƒƒãƒ”ãƒ³ã‚°
        self.recovery_strategies = {
            "RATE_LIMIT": RecoveryStrategy.BACKOFF,
            "SERVER_ERROR": RecoveryStrategy.RETRY,
            "NETWORK_ERROR": RecoveryStrategy.CIRCUIT_BREAKER,
            "AUTH_ERROR": RecoveryStrategy.FALLBACK
        }

    async def execute_with_recovery(
        self,
        operation: Callable,
        fallback_operation: Optional[Callable] = None,
        operation_id: str = "default",
        *args,
        **kwargs
    ) -> Any:
        """å¾©æ—§æ©Ÿèƒ½ä»˜ãã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""

        # ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãƒã‚§ãƒƒã‚¯
        if self.is_circuit_open(operation_id):
            if fallback_operation:
                return await self.execute_fallback(fallback_operation, *args, **kwargs)
            else:
                raise Exception(f"Circuit breaker open for {operation_id}")

        for attempt in range(self.config.max_retries + 1):
            try:
                result = await operation(*args, **kwargs)

                # æˆåŠŸæ™‚ã¯å¤±æ•—ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
                self.reset_failure_count(operation_id)
                return result

            except Exception as e:
                error_info = await self.analyzer.analyze(e)

                # æœ€å¾Œã®è©¦è¡Œã¾ãŸã¯éå¾©æ—§å¯èƒ½ã‚¨ãƒ©ãƒ¼
                if attempt == self.config.max_retries or not error_info.is_retryable:
                    self.record_failure(operation_id)

                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
                    if fallback_operation and self.should_use_fallback(error_info):
                        return await self.execute_fallback(fallback_operation, *args, **kwargs)

                    raise

                # å¾©æ—§æˆ¦ç•¥ã®å®Ÿè¡Œ
                await self.execute_recovery_strategy(error_info, attempt, operation_id)

        return None

    def is_circuit_open(self, operation_id: str) -> bool:
        """ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã®çŠ¶æ…‹ç¢ºèª"""

        if operation_id not in self.circuit_states:
            return False

        failure_count = self.failure_counts[operation_id]
        last_failure = self.last_failure_times.get(operation_id)

        if failure_count >= self.config.circuit_breaker_threshold:
            if last_failure and datetime.now() - last_failure < timedelta(seconds=self.config.circuit_breaker_timeout):
                return True
            else:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¾Œã¯ãƒªã‚»ãƒƒãƒˆ
                self.reset_failure_count(operation_id)
                return False

        return False

    def record_failure(self, operation_id: str):
        """å¤±æ•—ã®è¨˜éŒ²"""
        self.failure_counts[operation_id] += 1
        self.last_failure_times[operation_id] = datetime.now()

    def reset_failure_count(self, operation_id: str):
        """å¤±æ•—ã‚«ã‚¦ãƒ³ãƒˆã®ãƒªã‚»ãƒƒãƒˆ"""
        self.failure_counts[operation_id] = 0
        if operation_id in self.last_failure_times:
            del self.last_failure_times[operation_id]

    async def execute_recovery_strategy(self, error_info, attempt: int, operation_id: str):
        """å¾©æ—§æˆ¦ç•¥ã®å®Ÿè¡Œ"""

        strategy = self.recovery_strategies.get(
            error_info.category.value,
            RecoveryStrategy.RETRY
        )

        if strategy == RecoveryStrategy.BACKOFF:
            delay = min(
                self.config.base_delay * (self.config.backoff_multiplier ** attempt),
                self.config.max_delay
            )

            # Retry-Afterãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’å„ªå…ˆ
            if error_info.retry_after:
                delay = min(error_info.retry_after, self.config.max_delay)

            print(f"Exponential backoff: {delay}ç§’å¾…æ©Ÿ (è©¦è¡Œ {attempt + 1})")
            await asyncio.sleep(delay)

        elif strategy == RecoveryStrategy.RETRY:
            delay = self.config.base_delay * (attempt + 1)
            print(f"Simple retry: {delay}ç§’å¾…æ©Ÿ (è©¦è¡Œ {attempt + 1})")
            await asyncio.sleep(delay)

        elif strategy == RecoveryStrategy.CIRCUIT_BREAKER:
            # ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼çŠ¶æ…‹ã‚’è¨˜éŒ²
            self.record_failure(operation_id)
            print(f"Circuit breaker activated for {operation_id}")

            # çŸ­ã„å¾…æ©Ÿå¾Œã«ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
            await asyncio.sleep(1.0)

    def should_use_fallback(self, error_info) -> bool:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨ã®åˆ¤å®š"""

        fallback_categories = [
            "AUTH_ERROR",
            "INVALID_TOKEN",
            "SERVER_ERROR",
            "SERVICE_UNAVAILABLE"
        ]

        return error_info.category.value in fallback_categories

    async def execute_fallback(self, fallback_operation: Callable, *args, **kwargs) -> Any:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ“ä½œã®å®Ÿè¡Œ"""

        print("ğŸ”„ Executing fallback operation")

        try:
            result = await fallback_operation(*args, **kwargs)
            print("âœ… Fallback operation succeeded")
            return result
        except Exception as e:
            print(f"âŒ Fallback operation failed: {e}")
            raise

# LINE Bot ã§ã®ä½¿ç”¨ä¾‹
class ResilientLineBotService:
    """å¾©æ—§æ©Ÿèƒ½ä»˜ãLINE Botã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self, access_token: str, backup_token: str = None):
        self.access_token = access_token
        self.backup_token = backup_token

        self.recovery_system = SmartRecoverySystem(RecoveryConfig(
            max_retries=3,
            base_delay=1.0,
            backoff_multiplier=2.0,
            circuit_breaker_threshold=5
        ))

        # ãƒ—ãƒ©ã‚¤ãƒãƒªã¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        self.primary_api = self.create_api_client(access_token)
        self.backup_api = self.create_api_client(backup_token) if backup_token else None

    def create_api_client(self, token: str):
        """APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ä½œæˆ"""
        from linebot.v3.messaging import Configuration, ApiClient, MessagingApi

        if not token:
            return None

        configuration = Configuration(access_token=token)
        api_client = ApiClient(configuration)
        return MessagingApi(api_client)

    async def send_message_resilient(self, reply_token: str, message: str) -> bool:
        """å¾©æ—§æ©Ÿèƒ½ä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡"""

        async def primary_send():
            """ãƒ—ãƒ©ã‚¤ãƒãƒªAPIã§ã®é€ä¿¡"""
            return await self.primary_api.reply_message_async(
                ReplyMessageRequest(
                    reply_token=reply_token,
                    messages=[TextMessage(text=message)]
                )
            )

        async def fallback_send():
            """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—APIã§ã®é€ä¿¡"""
            if not self.backup_api:
                raise Exception("Backup API not available")

            return await self.backup_api.reply_message_async(
                ReplyMessageRequest(
                    reply_token=reply_token,
                    messages=[TextMessage(text=f"[BACKUP] {message}")]
                )
            )

        try:
            await self.recovery_system.execute_with_recovery(
                primary_send,
                fallback_send,
                "message_send"
            )
            return True

        except Exception as e:
            print(f"All message send attempts failed: {e}")
            return False

    async def get_profile_resilient(self, user_id: str) -> Optional[dict]:
        """å¾©æ—§æ©Ÿèƒ½ä»˜ããƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—"""

        async def primary_get_profile():
            """ãƒ—ãƒ©ã‚¤ãƒãƒªAPIã§ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—"""
            profile = await self.primary_api.get_profile_async(user_id)
            return {
                "display_name": profile.display_name,
                "user_id": profile.user_id,
                "picture_url": profile.picture_url,
                "status_message": profile.status_message
            }

        async def fallback_get_profile():
            """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤"""
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„DBã‹ã‚‰å–å¾—
            return {
                "display_name": "ãƒ¦ãƒ¼ã‚¶ãƒ¼",
                "user_id": user_id,
                "picture_url": None,
                "status_message": None
            }

        try:
            return await self.recovery_system.execute_with_recovery(
                primary_get_profile,
                fallback_get_profile,
                "profile_get"
            )

        except Exception as e:
            print(f"Profile retrieval failed: {e}")
            return None

# ä½¿ç”¨ä¾‹
async def demonstrate_resilient_service():
    """å¾©æ—§æ©Ÿèƒ½ã®å®Ÿæ¼”"""

    service = ResilientLineBotService(
        access_token="primary_token",
        backup_token="backup_token"
    )

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã®ãƒ†ã‚¹ãƒˆ
    success = await service.send_message_resilient(
        "reply_token_123",
        "Hello, World!"
    )

    if success:
        print("âœ… Message sent successfully")
    else:
        print("âŒ Message sending failed")

    # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—ã®ãƒ†ã‚¹ãƒˆ
    profile = await service.get_profile_resilient("user_123")

    if profile:
        print(f"âœ… Profile retrieved: {profile['display_name']}")
    else:
        print("âŒ Profile retrieval failed")
```

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

```python
import asyncio
import time
from typing import Dict, List, Any
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor

@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    average_response_time: float = 0.0
    peak_response_time: float = 0.0
    requests_per_second: float = 0.0
    memory_usage_mb: float = 0.0

class HighPerformanceErrorProcessor:
    """é«˜æ€§èƒ½ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, max_workers: int = 10, batch_size: int = 1000):
        self.max_workers = max_workers
        self.batch_size = batch_size

        # è¤‡æ•°ã®åˆ†æå™¨ã§ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°
        self.analyzers = [AsyncLineErrorAnalyzer() for _ in range(max_workers)]
        for analyzer in self.analyzers:
            analyzer.enable_caching(10000)

        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.metrics = PerformanceMetrics()
        self.response_times = []

        # ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼
        self.current_analyzer = 0

    def get_next_analyzer(self) -> AsyncLineErrorAnalyzer:
        """ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ã§åˆ†æå™¨ã‚’å–å¾—"""
        analyzer = self.analyzers[self.current_analyzer]
        self.current_analyzer = (self.current_analyzer + 1) % len(self.analyzers)
        return analyzer

    async def process_high_volume_errors(self, errors: List[dict]) -> List[dict]:
        """å¤§é‡ã‚¨ãƒ©ãƒ¼ã®é«˜é€Ÿå‡¦ç†"""

        start_time = time.time()

        # ã‚¨ãƒ©ãƒ¼ã‚’ãƒãƒƒãƒã«åˆ†å‰²
        batches = [
            errors[i:i + self.batch_size]
            for i in range(0, len(errors), self.batch_size)
        ]

        # ä¸¦è¡Œå‡¦ç†ã§ãƒãƒƒãƒã‚’å‡¦ç†
        tasks = []
        for batch in batches:
            analyzer = self.get_next_analyzer()
            task = asyncio.create_task(
                self.process_batch_with_metrics(analyzer, batch)
            )
            tasks.append(task)

        # å…¨ãƒãƒƒãƒã®å®Œäº†ã‚’å¾…æ©Ÿ
        batch_results = await asyncio.gather(*tasks, return_exceptions=True)

        # çµæœã‚’ãƒãƒ¼ã‚¸
        all_results = []
        for result in batch_results:
            if isinstance(result, Exception):
                print(f"Batch processing error: {result}")
                continue
            all_results.extend(result)

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
        end_time = time.time()
        processing_time = end_time - start_time

        self.update_performance_metrics(len(errors), len(all_results), processing_time)

        return all_results

    async def process_batch_with_metrics(
        self,
        analyzer: AsyncLineErrorAnalyzer,
        batch: List[dict]
    ) -> List[dict]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä»˜ããƒãƒƒãƒå‡¦ç†"""

        batch_start = time.time()

        try:
            # ãƒãƒƒãƒåˆ†æå®Ÿè¡Œ
            results = await analyzer.analyze_batch(batch, batch_size=len(batch))

            # çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
            processed_results = []
            for error, result in zip(batch, results):
                processed_results.append({
                    "original_error": error,
                    "analysis": result.to_dict(),
                    "processing_time_ms": (time.time() - batch_start) * 1000,
                    "analyzer_id": id(analyzer)
                })

            return processed_results

        except Exception as e:
            print(f"Batch processing error: {e}")
            return []

    def update_performance_metrics(
        self,
        total_errors: int,
        successful_errors: int,
        processing_time: float
    ):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ›´æ–°"""

        self.metrics.total_requests += total_errors
        self.metrics.successful_requests += successful_errors
        self.metrics.failed_requests += (total_errors - successful_errors)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®è¨˜éŒ²
        self.response_times.append(processing_time)
        if len(self.response_times) > 1000:  # æœ€æ–°1000ä»¶ã®ã¿ä¿æŒ
            self.response_times.pop(0)

        # å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“
        self.metrics.average_response_time = sum(self.response_times) / len(self.response_times)

        # ãƒ”ãƒ¼ã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“
        self.metrics.peak_response_time = max(self.response_times)

        # 1ç§’ã‚ãŸã‚Šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
        if processing_time > 0:
            self.metrics.requests_per_second = total_errors / processing_time

    def get_performance_report(self) -> dict:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""

        success_rate = 0
        if self.metrics.total_requests > 0:
            success_rate = (self.metrics.successful_requests / self.metrics.total_requests) * 100

        # åˆ†æå™¨ã”ã¨ã®çµ±è¨ˆ
        analyzer_stats = []
        for i, analyzer in enumerate(self.analyzers):
            stats = analyzer.get_analysis_stats()
            analyzer_stats.append({
                "analyzer_id": i,
                "total_analyzed": stats.get("total_analyzed", 0),
                "cache_hits": stats.get("cache_hits", 0),
                "cache_hit_rate": (
                    stats.get("cache_hits", 0) / stats.get("total_analyzed", 1) * 100
                )
            })

        return {
            "overall_metrics": {
                "total_requests": self.metrics.total_requests,
                "success_rate": round(success_rate, 2),
                "average_response_time_ms": round(self.metrics.average_response_time * 1000, 2),
                "peak_response_time_ms": round(self.metrics.peak_response_time * 1000, 2),
                "requests_per_second": round(self.metrics.requests_per_second, 2)
            },
            "analyzer_details": analyzer_stats,
            "configuration": {
                "max_workers": self.max_workers,
                "batch_size": self.batch_size,
                "active_analyzers": len(self.analyzers)
            }
        }

    async def adaptive_batch_sizing(self, errors: List[dict]) -> List[dict]:
        """é©å¿œçš„ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´"""

        # å°ã•ãªãƒãƒƒãƒã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        test_batch_size = min(100, len(errors))
        test_batch = errors[:test_batch_size]

        start_time = time.time()
        test_results = await self.process_high_volume_errors(test_batch)
        test_time = time.time() - start_time

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«åŸºã¥ã„ã¦ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’èª¿æ•´
        if test_time > 0:
            optimal_batch_size = int(test_batch_size / test_time * 0.5)  # 0.5ç§’ç›®æ¨™
            optimal_batch_size = max(50, min(2000, optimal_batch_size))  # ç¯„å›²åˆ¶é™

            print(f"Adaptive batch size: {optimal_batch_size} (based on test performance)")

            # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ›´æ–°
            original_batch_size = self.batch_size
            self.batch_size = optimal_batch_size

            try:
                # æ®‹ã‚Šã®ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†
                remaining_errors = errors[test_batch_size:]
                remaining_results = await self.process_high_volume_errors(remaining_errors)

                # çµæœã‚’ãƒãƒ¼ã‚¸
                all_results = test_results + remaining_results
                return all_results

            finally:
                # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¾©å…ƒ
                self.batch_size = original_batch_size

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šé€šå¸¸å‡¦ç†
        return await self.process_high_volume_errors(errors[test_batch_size:])

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ„ãƒ¼ãƒ«
class ErrorProcessingBenchmark:
    """ã‚¨ãƒ©ãƒ¼å‡¦ç†æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""

    def __init__(self):
        self.processor = HighPerformanceErrorProcessor(max_workers=8, batch_size=500)

    def generate_test_errors(self, count: int) -> List[dict]:
        """ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""

        error_templates = [
            {"status_code": 401, "message": "Authentication failed"},
            {"status_code": 400, "message": "Bad request", "error_code": "40010"},
            {"status_code": 429, "message": "Rate limit exceeded", "error_code": "42901"},
            {"status_code": 500, "message": "Internal server error"},
            {"status_code": 403, "message": "Forbidden"},
        ]

        errors = []
        for i in range(count):
            template = error_templates[i % len(error_templates)]
            error = template.copy()
            error["request_id"] = f"req_{i}"
            error["timestamp"] = time.time()
            errors.append(error)

        return errors

    async def run_benchmark(self, error_counts: List[int]) -> dict:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""

        benchmark_results = {}

        for count in error_counts:
            print(f"\nğŸ§ª Testing with {count:,} errors...")

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            test_errors = self.generate_test_errors(count)

            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
            start_time = time.time()
            results = await self.processor.process_high_volume_errors(test_errors)
            end_time = time.time()

            # çµæœè¨˜éŒ²
            processing_time = end_time - start_time
            errors_per_second = count / processing_time if processing_time > 0 else 0

            benchmark_results[count] = {
                "processing_time_seconds": round(processing_time, 3),
                "errors_per_second": round(errors_per_second, 1),
                "success_rate": len(results) / count * 100,
                "average_latency_ms": round(processing_time / count * 1000, 3)
            }

            print(f"âœ… Processed {len(results):,} errors in {processing_time:.3f}s")
            print(f"ğŸ“Š {errors_per_second:.1f} errors/sec")

        return benchmark_results

# ä½¿ç”¨ä¾‹ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
async def demonstrate_high_performance():
    """é«˜æ€§èƒ½å‡¦ç†ã®å®Ÿæ¼”"""

    benchmark = ErrorProcessingBenchmark()

    # æ®µéšçš„ãªè² è·ãƒ†ã‚¹ãƒˆ
    test_sizes = [100, 1000, 5000, 10000, 50000]

    print("ğŸš€ Starting performance benchmark...")
    results = await benchmark.run_benchmark(test_sizes)

    print("\nğŸ“Š Benchmark Results:")
    print("=" * 80)
    print(f"{'Errors':<10} {'Time(s)':<10} {'Errors/sec':<12} {'Success%':<10} {'Latency(ms)':<12}")
    print("=" * 80)

    for count, metrics in results.items():
        print(f"{count:<10,} {metrics['processing_time_seconds']:<10} "
              f"{metrics['errors_per_second']:<12} {metrics['success_rate']:<10.1f} "
              f"{metrics['average_latency_ms']:<12}")

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ
    performance_report = benchmark.processor.get_performance_report()
    print(f"\nğŸ“ˆ Performance Summary:")
    print(json.dumps(performance_report, indent=2))

# å®Ÿè¡Œ
if __name__ == "__main__":
    asyncio.run(demonstrate_high_performance())
```

## ã¾ã¨ã‚

ã“ã‚Œã‚‰ã®é«˜åº¦ãªä½¿ç”¨ä¾‹ã§ã¯ä»¥ä¸‹ã®å®Ÿè·µçš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã—ã¾ã—ãŸï¼š

### 1. ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®ç›£è¦–

- **ãƒãƒ«ãƒã‚µãƒ¼ãƒ“ã‚¹å¯¾å¿œ**: è¤‡æ•°ã® LINE Bot ã‚µãƒ¼ãƒ“ã‚¹ã®ä¸€å…ƒç®¡ç†
- **ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ **: é–¾å€¤ãƒ™ãƒ¼ã‚¹ã®è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆ
- **çµ±è¨ˆã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªç›£è¦–ãƒ‡ãƒ¼ã‚¿

### 2. è‡ªå‹•å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ 

- **å¾©æ—§æˆ¦ç•¥**: ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥ã®é©å¿œçš„ãªå¾©æ—§
- **ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼**: éšœå®³ã®é€£é–ã‚’é˜²ãä¿è­·æ©Ÿèƒ½
- **ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã¸ã®è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

- **ä¸¦è¡Œå‡¦ç†**: ãƒãƒ«ãƒãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã‚‹é«˜é€ŸåŒ–
- **é©å¿œçš„ãƒãƒƒãƒã‚µã‚¤ã‚º**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«åŸºã¥ãè‡ªå‹•èª¿æ•´
- **è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: æ€§èƒ½ç›£è¦–ã¨æœ€é©åŒ–æŒ‡æ¨™

ã“ã‚Œã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€æœ¬æ ¼çš„ãªãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ä½¿ç”¨ã§ãã‚‹å …ç‰¢ã§é«˜æ€§èƒ½ãª LINE Bot ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚

æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:

- **[å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾‹](real_world.md)** - å…·ä½“çš„ãªå®Ÿè£…ä¾‹
- **[ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](../errors/troubleshooting.md)** - å•é¡Œè§£æ±ºã‚¬ã‚¤ãƒ‰
- **[ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°](performance_tuning.md)** - ã•ã‚‰ãªã‚‹æœ€é©åŒ–æ‰‹æ³•
